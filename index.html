<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="vbZtDOM4X8GSoh1XS-em9jtdkGzpSjItj_fWbRyVm9M"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Nishant Balepur</title> <meta name="author" content="Nishant Balepur"> <meta name="description" content="My personal website :)"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%AB%A0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nbalepur.github.io//"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Nishant</span> Balepur </h1> <p class="desc">Ph.D. Student in Computer Science at <a href="https://umd.edu/" rel="external nofollow noopener" target="_blank">University of Maryland, College Park</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/profile-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/profile-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/profile-1400.webp"></source> <img src="/assets/img/profile.png?8496867ec3c4582fe1e4de706518a504" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="profile.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>Email:</p> <p>nbalepur[at]umd[dot]edu</p> </div> </div> <div class="clearfix"> <p>Hi! My name is Nishant and I’m a second-year Ph.D. student at the University of Maryland, where I am fortunate to be advised by Professors <strong><a href="http://users.umiacs.umd.edu/~jbg/" rel="external nofollow noopener" target="_blank">Jordan Boyd-Grayber</a></strong> and <strong><a href="https://rudinger.github.io/" rel="external nofollow noopener" target="_blank">Rachel Rudinger</a></strong>. I also collaborate closely with Professor <strong><a href="https://ihsgnef.github.io/" rel="external nofollow noopener" target="_blank">Shi Feng</a></strong> at GWU. I am graciously supported by the <a href="https://www.nsfgrfp.org/" rel="external nofollow noopener" target="_blank">NSF GRFP</a> and a <a href="https://cohere.com/blog/c4ai-research-grants" rel="external nofollow noopener" target="_blank">Cohere For AI Research Grant</a>.</p> <p>I am (super broadly) working on aligning and evaluating LLMs (or <a href="https://www.youtube.com/watch?v=u0DgoRVLTE8" rel="external nofollow noopener" target="_blank">Muppets</a>). My research can be grouped into 3 questions:</p> <ol> <li>How can we make models more <strong>factual</strong>? [<a href="https://arxiv.org/abs/2305.03276" rel="external nofollow noopener" target="_blank">expository text (EMNLP’23)</a>, <a href="https://arxiv.org/abs/2310.14486" rel="external nofollow noopener" target="_blank">fact transfer (EMNLP’23)</a>]</li> <li>How can we guide models toward <strong>downstream user goals</strong>? [<a href="https://aclanthology.org/2023.findings-acl.14/" rel="external nofollow noopener" target="_blank">topic mining (ACL’23)</a>, <a href="https://arxiv.org/abs/2402.12291" rel="external nofollow noopener" target="_blank">flashcards (EMNLP’24)</a>, <a href="https://arxiv.org/abs/2406.15352" rel="external nofollow noopener" target="_blank">mnemonics (EMNLP’24)</a>]</li> <li>How can evaluations expose model <strong>weaknesses</strong>? [<a href="https://arxiv.org/abs/2311.07532" rel="external nofollow noopener" target="_blank">process of elimination (ACL’24)</a>, <a href="https://arxiv.org/abs/2402.12483" rel="external nofollow noopener" target="_blank">MCQA shortcuts (ACL’24)</a>, <a href="https://arxiv.org/abs/2407.01992" rel="external nofollow noopener" target="_blank">MCQA benchmark cheating (ACL’24)</a>]</li> </ol> <p>If you’ve encountered another “Balepur, N” during your literature search, you may be looking for <a href="https://nainasb.github.io/" rel="external nofollow noopener" target="_blank">my sister</a> 😛</p> </div> <br> <h2><a href="/publications/" style="color: inherit;">📝 Selected Publications</a></h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#fac919">EMNLP 2024</abbr></div> <div id="balepur2024smart" class="col-sm-8"> <div class="title">A SMART Mnemonic Sounds like "Glue Tonic": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick</div> <div class="author"> <em>Nishant Balepur</em>, Matthew Shu, Alexander Hoyle, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Alison Robey, Shi Feng, Seraphina Goldfarb-Tarrant, Jordan Boyd-Graber' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2406.15352.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2406.15352"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Keyword mnemonics are memorable explanations that link new terms to simpler keywords. Prior works generate mnemonics for students, but they do not guide models toward mnemonics students prefer and aid learning. We build SMART, a mnemonic generator trained on feedback from real students learning new terms. To train SMART, we first fine-tune LLaMA-2 on a curated set of user-written mnemonics. We then use LLM alignment to enhance SMART: we deploy mnemonics generated by SMART in a flashcard app to find preferences on mnemonics students favor. We gather 2684 preferences from 45 students across two types: expressed (inferred from ratings) and observed (inferred from student learning), yielding three key findings. First, expressed and observed preferences disagree; what students think is helpful does not fully capture what is truly helpful. Second, Bayesian models can synthesize complementary data from multiple preference types into a single effectiveness signal. SMART is tuned via Direct Preference Optimization on this signal, which we show resolves ties and missing labels in the typical method of pairwise comparisons, augmenting data for LLM output quality gains. Third, mnemonic experts assess SMART as matching GPT-4, at much lower deployment costs, showing the utility of capturing diverse student feedback to align LLMs in education.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">balepur2024smart</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A SMART Mnemonic Sounds like "Glue Tonic": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Shu, Matthew and Hoyle, Alexander and Robey, Alison and Feng, Shi and Goldfarb-Tarrant, Seraphina and Boyd-Graber, Jordan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2406.15352}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC3535">ACL 2024</abbr></div> <div id="balepur-etal-2024-artifacts" class="col-sm-8"> <div class="title">Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?</div> <div class="author"> <em>Nishant Balepur</em>, Abhilasha Ravichander, and Rachel Rudinger</div> <div class="periodical"> <em>In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Aug 2024 </div> <div class="periodical"> </div> <div style="color:red;"><b>Best Paper Award (4%) and Oral (7%) at MASC-SSL 2024</b></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.acl-long.555.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Multiple-choice question answering (MCQA) is often used to evaluate large language models (LLMs). To see if MCQA assesses LLMs as intended, we probe if LLMs can perform MCQA with choices-only prompts, where models must select the correct answer only from the choices. In three MCQA datasets and four LLMs, this prompt bests a majority baseline in 11/12 cases, with up to 0.33 accuracy gain. To help explain this behavior, we conduct an in-depth, black-box analysis on memorization, choice dynamics, and question inference. Our key findings are threefold. First, we find no evidence that the choices-only accuracy stems from memorization alone. Second, priors over individual choices do not fully explain choices-only accuracy, hinting that LLMs use the group dynamics of choices. Third, LLMs have some ability to infer a relevant question from choices, and surprisingly can sometimes even match the original question. We hope to motivate the use of stronger baselines in MCQA benchmarks, the design of robust MCQA datasets, and further efforts to explain LLM decision-making.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#fac919">EMNLP 2023</abbr></div> <div id="balepur2023expository" class="col-sm-8"> <div class="title">Expository Text Generation: Imitate, Retrieve, Paraphrase</div> <div class="author"> <em>Nishant Balepur</em>, Jie Huang, and Kevin Chen-Chuan Chang</div> <div class="periodical"> <em>In The 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023</em>, Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2305.03276.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/6elNaka-JKM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Expository documents are vital resources for conveying complex information to readers. Despite their usefulness, writing expository documents by hand is a time-consuming and labor-intensive process that requires knowledge of the domain of interest, careful content planning, and the ability to synthesize information from multiple sources. To ease these burdens, we introduce the task of expository text generation, which seeks to automatically generate an accurate and informative expository document from a knowledge source. We solve our task by developing IRP, an iterative framework that overcomes the limitations of language models and separately tackles the steps of content planning, fact selection, and rephrasing. Through experiments on three diverse datasets, we demonstrate that IRP produces high-quality expository documents that accurately inform readers.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur2023expository</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Expository Text Generation: Imitate, Retrieve, Paraphrase}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Huang, Jie and Chang, Kevin Chen-Chuan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://youtu.be/6elNaka-JKM}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <div class="news"> <h2>🥳 Research Highlights</h2> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Sep 19, 2024</th> <td> Three papers accepted to EMNLP (2 main, 1 findings) on <a href="https://arxiv.org/abs/2406.15352" rel="external nofollow noopener" target="_blank">Aligning LLMs for Mnemonic Generation</a>, <a href="https://arxiv.org/abs/2402.12291" rel="external nofollow noopener" target="_blank">NLP-Powered Flashcard Scheduling</a>, and MCQA Quality Analysis. Super grateful to my advisors and collaborators! </td> </tr> <tr> <th scope="row">Jun 23, 2024</th> <td> Our paper on aligning LLMs for mnemonic generation through student learning preferences is now on Arxiv! View the preprint here: <a href="https://arxiv.org/abs/2406.15352" rel="external nofollow noopener" target="_blank">A SMART Mnemonic Sounds like “Glue Tonic”: Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick</a> </td> </tr> <tr> <th scope="row">May 16, 2024</th> <td> Three papers on LLM MCQA reasoning accepted to ACL 2024! 1) <a href="https://arxiv.org/abs/2402.12483" rel="external nofollow noopener" target="_blank">Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?</a> (main); 2) <a href="https://arxiv.org/abs/2311.07532" rel="external nofollow noopener" target="_blank">It’s Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning</a> (findings); 3) <a href="https://www.arxiv.org/abs/2407.01992" rel="external nofollow noopener" target="_blank">Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?</a> (KnowLM workshop) </td> </tr> <tr> <th scope="row">May 3, 2024</th> <td> Presented our work <a href="https://arxiv.org/abs/2402.12483" rel="external nofollow noopener" target="_blank">Aritfacts or Abduction</a> for <a href="https://www.mascsll.org/" rel="external nofollow noopener" target="_blank">MASC 2024</a> at Hopkins (1 of 5 selected orals). Also extremely grateful to be selected for 1 of 3 <a href="https://nbalepur.github.io/assets/img/MASC.jpg" target="_blank">best paper awards</a>! You can view my slides <a href="https://nbalepur.github.io/assets/pdf/Artifacts_or_Abduction.pdf" target="_blank">here</a> </td> </tr> <tr> <th scope="row">Apr 22, 2024</th> <td> Awarded a <a href="https://cohere.com/blog/c4ai-research-grants" rel="external nofollow noopener" target="_blank">Cohere For AI Research Grant</a> for our NLP+Education work with <a target="_blank" href="https://nbalepur.github.io/assets/html/KARL.html">KAR³L</a>. Excited for this collaboration! </td> </tr> </table> </div> </div> <br> <div class="news"> <h2>😔 Negative Results</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Apr 15, 2024</th> <td> <a href="https://arxiv.org/abs/2402.12291" rel="external nofollow noopener" target="_blank">One paper</a> not committed to ACL 2024 </td> </tr> <tr> <th scope="row">Feb 15, 2024</th> <td> <a href="https://arxiv.org/abs/2311.07532" rel="external nofollow noopener" target="_blank">Two</a> <a href="https://arxiv.org/abs/2402.12291" rel="external nofollow noopener" target="_blank">papers</a> not committed to NAACL 2024 </td> </tr> <tr> <th scope="row">Oct 6, 2023</th> <td> <a href="https://arxiv.org/abs/2305.14750" rel="external nofollow noopener" target="_blank">One paper</a> rejected from EMNLP 2023 </td> </tr> <tr> <th scope="row">Mar 20, 2023</th> <td> My first ever review score of 1 recieved on an <a href="https://arxiv.org/abs/2305.03276" rel="external nofollow noopener" target="_blank">ARR submission</a> </td> </tr> </table> </div> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6E%62%61%6C%65%70%75%72@%75%6D%64.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=G8_fojUAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/nbalepur" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://twitter.com/NishantBalepur" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> Email is the best way to reach me! </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Nishant Balepur. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1BY15F84QB"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1BY15F84QB");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>