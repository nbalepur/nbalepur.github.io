<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="vbZtDOM4X8GSoh1XS-em9jtdkGzpSjItj_fWbRyVm9M"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Nishant Balepur</title> <meta name="author" content="Nishant Balepur"> <meta name="description" content="My personal website :)"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/drama.png"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nbalepur.github.io//publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Nishant </span>Balepur</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#497174">Under Review</abbr></div> <div id="balepur2025language" class="col-sm-8"> <div class="title">Language Models Dont́ Know What You Want: Evaluating Personalization in Deep Research Needs Real Users</div> <div class="author"> <em>Nishant Balepur</em>, Malachi Hamada, Varsha Kishore, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Sergey Feldman, Amanpreet Singh, Pao Siangliulue, Joseph Chee Chang, Eunsol Choi, Jordan Lee Boyd-Graber, Aakanksha Naik' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#497174">Under Review</abbr></div> <div id="balepur2025strategic" class="col-sm-8"> <div class="title">Test-Time Reasoners Are Strategic Multiple-Choice Test-Takers</div> <div class="author"> <em>Nishant Balepur</em>, Atrey Desai, and Rachel Rudinger</div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://nbalepur.github.io/assets/pdf/ttr_choices_only.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="tldr hidden"> <p>We reveal test-time reasoners can answer multiple-choice questions without the question, but not always via problematic shortcuts</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#497174">Under Review</abbr></div> <div id="bragg2025astabench" class="col-sm-8"> <div class="title">AstaBench: Rigorous Benchmarking of AI Agents with a Holistic Scientific Research Suite</div> <div class="author"> Jonathan Bragg, Mike D’Arcy, <em>Nishant Balepur</em>, and <span class="more-authors" title="click to view 35 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '35 more authors' ? 'Dan Bareket, Bhavana Dalvi, Sergey Feldman, Dany Haddad, Jena D. Hwang, Peter Jansen, Varsha Kishore, Bodhisattwa Prasad Majumder, Aakanksha Naik, Sigal Rahamimov, Kyle Richardson, Amanpreet Singh, Harshit Surana, Aryeh Tiktinsky, Rosni Vasu, Guy Wiener, Chloe Anastasiades, Stefan Candra, Jason Dunkelberger, Dan Emery, Rob Evans, Regan Huff, Rodney Kinney, Matt Latzke, Jaron Lochner, Ruben Lozano-Aguilera, Cecile Nguyen, Smita Rao, Amber Tanaka, Brooke Vlahos, Peter Clark, Doug Downey, Yoav Goldberg, Ashish Sabharwal, Daniel S. Weld' : '35 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">35 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://www.datocms-assets.com/64837/1756213171-astabench-16.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="tldr hidden"> <p>We build a rigorous benchmark to measure scientific progress in research agents</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#497174">Under Review</abbr></div> <div id="han2025Measuring" class="col-sm-8"> <div class="title">Measuring Users’ Mental Models of Speech Translation in Human-MT Collaboration</div> <div class="author"> Hyojung Han, <em>Nishant Balepur</em>, Jordan Lee Boyd-Graber, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Marine Carpuat' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="tldr hidden"> <p>We study how users can build mental models of speech translation systems in collaborative question answering</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#fcbe14">EMNLP 2025</abbr></div> <div id="balepur2025planorama" class="col-sm-8"> <div class="title">A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users</div> <div class="author"> <em>Nishant Balepur</em>, Matthew Shu, Yoo Yeon Sung, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Seraphina Goldfarb-Tarrant, Shi Feng, Fumeng Yang, Rachel Rudinger, Jordan Lee Boyd-Graber' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a href="https://nbalepur.github.io/assets/pdf/Planorama.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="tldr hidden"> <p>We show user preferences, reward models, and agent simulations all completely fail to predict what actually helps users</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#497174">Under Review</abbr></div> <div id="schulhoff2025jailbreak" class="col-sm-8"> <div class="title">A Survey on LLM Jailbreaking Attacks and Defenses</div> <div class="author"> Sander Schulhoff*, <em>Nishant Balepur*</em>, Arjun Akkiraju, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Michael Ilie, Konstantine Kahadze, Rob Voigt, Denis Peskoff' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>GenAI systems are designed to safely address users’ needs specified in input prompts, but these same prompts can be carefully manipulated to elicit harmful behaviors from the target system, a phenomenon commonly referred to as prompt hacking or jailbreaking. Such attacks pose security and reliability concerns, as malicious end users and third parties can circumvent model safeguards and obtain responses that spread misinformation, include dangerous information, or steal end-user data. The nature of these attacks is ever-growing, with many being proposed in academia each year, and even more “in the wild” on the Internet. In this paper, we introduce a comprehensive taxonomy that categorizes emerging prompt attacks and defense mechanisms. Our goal is to provide a structured foundation for future work and highlight the urgency of addressing GenAI security challenges.</p> </div> <div class="tldr hidden"> <p>We review how researchers and users in-the-wild attack LLMs and defend against them, and discuss future work in the context of GenAI advancements</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC3535">ACL 2025</abbr></div> <div id="balepur-etal-2025-best" class="col-sm-8"> <div class="title">Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above</div> <div class="author"> <em>Nishant Balepur</em>, Rachel Rudinger, and Jordan Lee Boyd-Graber</div> <div class="periodical"> <em>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Jul 2025 </div> <div class="periodical"> </div> <div style="color:red;"><b>Oral at ACL 2025, Best Paper Award and Oral (1.5%) at MASC-SLL 2025</b></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2502.14127" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.18653/v1/2025.acl-long.169"></span> <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2025.acl-long.169" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Multiple choice question answering (MCQA) is popular for LLM evaluation due to its simplicity and human-like testing, but we argue for its reform. We first reveal flaws in MCQA’s format, as it struggles to: 1) test generation/subjectivity; 2) match LLM use cases; and 3) fully test knowledge. We instead advocate for generative formats based on human testing—where LLMs construct and explain answers—better capturing user needs and knowledge while remaining easy to score. We then show even when MCQA is a useful format, its datasets suffer from: leakage; unanswerability; shortcuts; and saturation. In each issue, we give fixes from education, like rubrics to guide MCQ writing; scoring methods to bridle guessing; and Item Response Theory to build harder MCQs. Lastly, we discuss LLM errors in MCQA—robustness, biases, and unfaithful explanations—showing how our prior solutions better measure or address these issues. While we do not need to desert MCQA, we encourage more efforts in refining the task based on educational testing, advancing evaluations.</p> </div> <div class="tldr hidden"> <p>We review and critique current multiple-choice evaluation practices, and borrow insights from education research to propose solutions</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur-etal-2025-best</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Which of These Best Describes Multiple Choice Evaluation with {LLM}s? A) Forced {B}) Flawed {C}) Fixable {D}) All of the Above}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Rudinger, Rachel and Boyd-Graber, Jordan Lee}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vienna, Austria}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2025.acl-long.169}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3394--3418}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{979-8-89176-251-0}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We review and critique current multiple-choice evaluation practices, and borrow insights from education research to propose solutions}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{I think this is my best argued paper, especially since we had to survey results from existing papers and come up with our own arguments. I think finishing this made me a much better writer!}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC3535">ACL 2025</abbr></div> <div id="balepur-etal-2025-whose" class="col-sm-8"> <div class="title">Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas</div> <div class="author"> <em>Nishant Balepur</em>, Vishakh Padmakumar, Fumeng Yang, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Shi Feng, Rachel Rudinger, Jordan Lee Boyd-Graber' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Jul 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2501.11549" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.18653/v1/2025.acl-long.168"></span> <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2025.acl-long.168" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>LLMs are tuned to follow instructions (aligned) by learning which of two outputs users prefer for a prompt. However, this preference data format does not convey why users prefer responses that are chosen or rejected, so LLMs trained on these datasets cannot tailor responses to varied user needs. To surface these parameters of personalization, we apply abductive reasoning to preference data, inferring needs and interests of users, i.e. personas, that may prefer each output. We test this idea in two steps: Persona Inference (PI)—abductively inferring personas of users who prefer chosen or rejected outputs—and Persona Tailoring (PT)—training models to tailor responses to personas from PI. We find: 1) LLMs infer personas accurately explaining why different users may prefer both chosen or rejected outputs; 2) Training on preference data augmented with PI personas via PT boosts personalization, enabling models to support user-written personas; and 3) Rejected response personas form harder personalization evaluations, showing PT better aids users with uncommon preferences versus typical alignment methods. We argue for an abductive view of preferences for personalization, asking not only which response is better but when, why, and for whom.</p> </div> <div class="tldr hidden"> <p>We propose a data augmentation strategy of abductive persona inference to improve personalization in direct preference optimization</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur-etal-2025-whose</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Padmakumar, Vishakh and Yang, Fumeng and Feng, Shi and Rudinger, Rachel and Boyd-Graber, Jordan Lee}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vienna, Austria}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2025.acl-long.168}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3371--3393}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{979-8-89176-251-0}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We propose a data augmentation strategy of abductive persona inference to improve personalization in direct preference optimization}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#6087e0">NAACL 2025</abbr></div> <div id="balepur-etal-2025-reverse" class="col-sm-8"> <div class="title">Reverse Question Answering: Can an LLM Write a Question so Hard (or Bad) that it Can‘t Answer?</div> <div class="author"> <em>Nishant Balepur</em>, Feng Gu, Abhilasha Ravichander, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Shi Feng, Jordan Lee Boyd-Graber, Rachel Rudinger' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers)</em>, Apr 2025 </div> <div class="periodical"> </div> <div style="color:red;"><b>Oral</b></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2410.15512" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-isbn="979-8-89176-190-2"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Question answering (QA)—producing correct answers for input questions—is popular, but we test a reverse question answering (RQA) task: given an input answer, generate a question with that answer. Past work tests QA and RQA separately, but we test them jointly, comparing their difficulty, aiding benchmark design, and assessing reasoning consistency. 16 LLMs run QA and RQA with trivia questions/answers, showing: 1) Versus QA, LLMs are much less accurate in RQA for numerical answers, but slightly more accurate in RQA for textual answers; 2) LLMs often answer their own invalid questions from RQA accurately in QA, so RQA errors are not from knowledge gaps alone; 3) RQA errors correlate with question difficulty and inversely correlate with answer frequencies in the Dolma corpus; and 4) LLMs struggle to give valid multi-hop questions. By finding question and answer types yielding RQA errors, we suggest improvements for LLM RQA reasoning.</p> </div> <div class="tldr hidden"> <p>We find a surprising LLM weakness in reverse question answering: given an answer, can an LLM generate any valid question with that answer?</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur-etal-2025-reverse</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reverse Question Answering: Can an {LLM} Write a Question so Hard (or Bad) that it Can`t Answer?}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Gu, Feng and Ravichander, Abhilasha and Feng, Shi and Boyd-Graber, Jordan Lee and Rudinger, Rachel}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Chiruzzo, Luis and Ritter, Alan and Wang, Lu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Albuquerque, New Mexico}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2025.naacl-short.5/}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{44--64}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{979-8-89176-190-2}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We find a surprising LLM weakness in reverse question answering: given an answer, can an LLM generate any valid question with that answer?}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{I think this paper has the weirdest / most surprising results. That is, I didn't think that so many LLMs wouldn't be able to generate questions for numbers when playing around with ChatGPT}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#6087e0">NAACL 2025</abbr></div> <div id="balepur-etal-2025-mods" class="col-sm-8"> <div class="title">MoDS: Moderating a Mixture of Document Speakers to Summarize Debatable Queries in Document Collections</div> <div class="author"> <em>Nishant Balepur</em>, Alexa Siu, Nedim Lipka, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Franck Dernoncourt, Tong Sun, Jordan Lee Boyd-Graber, Puneet Mathur' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</em>, Apr 2025 </div> <div class="periodical"> </div> <div style="color:red;"><b>Oral</b></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2502.00322" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-isbn="979-8-89176-189-6"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Query-focused summarization (QFS) gives a summary of documents to answer a query. Past QFS work assumes queries have one answer, ignoring debatable ones (Is law school worth it?). We introduce Debatable QFS (DQFS), a task to create summaries that answer debatable queries via documents with opposing perspectives; summaries must comprehensively cover all sources and balance perspectives, favoring no side. These goals elude LLM QFS systems, which: 1) lack structured content plans, failing to guide LLMs to write balanced summaries, and 2) use the same query to retrieve contexts across documents, failing to cover all perspectives specific to each document’s content. To overcome this, we design MODS, a multi-LLM framework mirroring human panel discussions. MODS treats documents as individual Speaker LLMs and has a Moderator LLM that picks speakers to respond to tailored queries for planned topics. Speakers use tailored queries to retrieve relevant contexts from their documents and supply perspectives, which are tracked in a rich outline, yielding a content plan to guide the final summary. Experiments on ConflictingQA with controversial web queries and DebateQFS, our new dataset of debate queries from Debatepedia, show MODS beats SOTA by 38-59% in topic paragraph coverage and balance, based on new citation metrics. Users also find MODS’s summaries to be readable and more balanced.</p> </div> <div class="tldr hidden"> <p>We propose a new task of answering debatable queries (Are EVs good?) from documents and use multi-agent summarization to reach SOTA</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur-etal-2025-mods</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{M}o{DS}: Moderating a Mixture of Document Speakers to Summarize Debatable Queries in Document Collections}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Siu, Alexa and Lipka, Nedim and Dernoncourt, Franck and Sun, Tong and Boyd-Graber, Jordan Lee and Mathur, Puneet}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Chiruzzo, Luis and Ritter, Alan and Wang, Lu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Albuquerque, New Mexico}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2025.naacl-long.20/}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{465--491}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{979-8-89176-189-6}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We propose a new task of answering debatable queries (Are EVs good?) from documents and use multi-agent summarization to reach SOTA}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#fcbe14">EMNLP 2024</abbr></div> <div id="balepur-etal-2024-smart" class="col-sm-8"> <div class="title">A SMART Mnemonic Sounds like “Glue Tonic”: Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick</div> <div class="author"> <em>Nishant Balepur</em>, Matthew Shu, Alexander Hoyle, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Alison Robey, Shi Feng, Seraphina Goldfarb-Tarrant, Jordan Lee Boyd-Graber' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2406.15352.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Keyword mnemonics are memorable explanations that link new terms to simpler keywords.Prior work generates mnemonics for students, but they do not train models using mnemonics students prefer and aid learning.We build SMART, a mnemonic generator trained on feedback from real students learning new terms.To train SMART, we first fine-tune LLaMA-2 on a curated set of user-written mnemonics.We then use LLM alignment to enhance SMART: we deploy mnemonics generated by SMART in a flashcard app to find preferences on mnemonics students favor. We gather 2684 preferences from 45 students across two types: **expressed** (inferred from ratings) and **observed** (inferred from student learning), yielding three key findings.First, expressed and observed preferences disagree; what students *think* is helpful does not always capture what is *truly* helpful.Second, Bayesian models can synthesize complementary data from multiple preference types into a single effectiveness signal.SMART is tuned via Direct Preference Optimization on this signal, which resolves ties and missing labels in the typical method of pairwise comparisons, augmenting data for LLM output quality gains. Third, mnemonic experts assess SMART as matching GPT-4 at much lower deployment costs, showing the utility of capturing diverse student feedback to align LLMs in education.</p> </div> <div class="tldr hidden"> <p>We generate mnemonics by aligning an LLM using preferences from 47 GRE test-takers on the mnemonics they like and which mnemonics aid learning</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur-etal-2024-smart</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A {SMART} Mnemonic Sounds like {``}Glue Tonic{''}: Mixing {LLM}s with Student Feedback to Make Mnemonic Learning Stick}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Shu, Matthew and Hoyle, Alexander and Robey, Alison and Feng, Shi and Goldfarb-Tarrant, Seraphina and Boyd-Graber, Jordan Lee}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Miami, Florida, USA}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.emnlp-main.786}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We generate mnemonics by aligning an LLM using preferences from 47 GRE test-takers on the mnemonics they like and which mnemonics aid learning}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{This was the first paper in my Ph.D. I was super proud of. It felt pretty ambitious on my end---working on a new task, collecting our own data with real students, some new modeling decisions, and bothering experts to help us evaluate---as in my undergrad, I worked on a lot of safe / SOTA type papers on offline benchmarks. This paper also got me in the habit of writing self-referential titles! (thanks jbg)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{14202--14225}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#fcbe14">EMNLP 2024</abbr></div> <div id="shu-etal-2024-karl" class="col-sm-8"> <div class="title">KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students</div> <div class="author"> Matthew Shu*, <em>Nishant Balepur*</em>, Shi Feng, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jordan Lee Boyd-Graber' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2402.12291.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Flashcard schedulers rely on 1) *student models* to predict the flashcards a student knows; and 2) *teaching policies* to pick which cards to show next via these predictions.Prior student models, however, just use study data like the student’s past responses, ignoring the text on cards. We propose **content-aware scheduling**, the first schedulers exploiting flashcard content.To give the first evidence that such schedulers enhance student learning, we build KARL, a simple but effective content-aware student model employing deep knowledge tracing (DKT), retrieval, and BERT to predict student recall.We train KARL by collecting a new dataset of 123,143 study logs on diverse trivia questions.KARL bests existing student models in AUC and calibration error.To ensure our improved predictions lead to better student learning, we create a novel delta-based teaching policy to deploy KARL online.Based on 32 study paths from 27 users, KARL improves learning efficiency over SOTA, showing KARL’s strength and encouraging researchers to look beyond historical study data to fully capture student abilities.</p> </div> <div class="tldr hidden"> <p>We design the first flashcard scheduler that uses LLMs and the text on the flashcards, and use this model to help 500+ students learn</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shu-etal-2024-karl</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{KARL}: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shu, Matthew and Balepur, Nishant and Feng, Shi and Boyd-Graber, Jordan Lee}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Miami, Florida, USA}</span><span class="p">,</span>
  <span class="na">is_first_author</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.emnlp-main.784}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{This was the hardest paper to publish during my Ph.D. so far---took around 5 submissions? Matthew (the undergrad leading this project) did a lot of great work getting results for this project, but I really struggled to publish it, since education was not (and still is not) my area of expertise. But I think I learned how to better respond to criticism and not care much what reviewers think ¯\_(ツ)_/¯. I think if I was a better writer at the time I could have made this paper more impactful, but still super proud of it!}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We design the first flashcard scheduler that uses LLMs and the text on the flashcards, and use this model to help 500+ students learn}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{14161--14178}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#fcbe14">EMNLP 2024</abbr></div> <div id="palta-etal-2024-plausibly" class="col-sm-8"> <div class="title">Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning</div> <div class="author"> Shramay Palta, <em>Nishant Balepur</em>, Peter Rankel, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Sarah Wiegreffe, Marine Carpuat, Rachel Rudinger' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EMNLP 2024</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2410.10854" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.18653/v1/2024.findings-emnlp.198"></span> <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2024.findings-emnlp.198" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Questions involving commonsense reasoning about everyday situations often admit many possible or plausible answers. In contrast, multiple-choice question (MCQ) benchmarks for commonsense reasoning require a hard selection of a single correct answer, which, in principle, should represent the most plausible answer choice. On 250 MCQ items sampled from two commonsense reasoning benchmarks, we collect 5,000 independent plausibility judgments on answer choices. We find that for over 20% of the sampled MCQs, the answer choice rated most plausible does not match the benchmark gold answers; upon manual inspection, we confirm that this subset exhibits higher rates of problems like ambiguity or semantic mismatch between question and answer choices. Experiments with LLMs reveal low accuracy and high variation in performance on the subset, suggesting our plausibility criterion may be helpful in identifying more reliable benchmark items for commonsense evaluation.</p> </div> <div class="tldr hidden"> <p>We show that the gold answer in commonsense multiple-choice datasets is not always the one perceived to be the most plausible</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">palta-etal-2024-plausibly</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Palta, Shramay and Balepur, Nishant and Rankel, Peter and Wiegreffe, Sarah and Carpuat, Marine and Rudinger, Rachel}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: EMNLP 2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Miami, Florida, USA}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.findings-emnlp.198/}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2024.findings-emnlp.198}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3451--3473}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We show that the gold answer in commonsense multiple-choice datasets is not always the one perceived to be the most plausible}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#497174">Technical Report</abbr></div> <div id="schulhoff2024prompt" class="col-sm-8"> <div class="title">The Prompt Report: A Systematic Survey of Prompting Techniques</div> <div class="author"> Sander Schulhoff, Michael Ilie, <em>Nishant Balepur</em>, and <span class="more-authors" title="click to view 28 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '28 more authors' ? 'Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, HyoJung Han, Sevien Schulhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara, Dayeon Ki, Sweta Agrawal, Chau Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava, Hevander Da Costa, Saloni Gupta, Megan L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker, Denis Peskoff, Marine Carpuat, Jules White, Shyamal Anadkat, Alexander Hoyle, Philip Resnik' : '28 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">28 more authors</span> </div> <div class="periodical"> Nov 2024 </div> <div class="periodical"> </div> <div style="color:red;"><b>Huggingface #1 Paper of the Day</b></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2406.06608.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Generative Artificial Intelligence (GenAI) systems are being increasingly deployed across all parts of industry and research settings. Developers and end users interact with these systems through the use of prompting or prompt engineering. While prompting is a widespread and highly researched concept, there exists conflicting terminology and a poor ontological understanding of what constitutes a prompt due to the area’s nascency. This paper establishes a structured understanding of prompts, by assembling a taxonomy of prompting techniques and analyzing their use. We present a comprehensive vocabulary of 33 vocabulary terms, a taxonomy of 58 text-only prompting techniques, and 40 techniques for other modalities. We further present a meta-analysis of the entire literature on natural language prefix-prompting.</p> </div> <div class="tldr hidden"> <p>We survey current techniques and practices when prompting generative AI systems like ChatGPT</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">schulhoff2024prompt</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Prompt Report: A Systematic Survey of Prompting Techniques}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and Dulepet, Pranav Sandeep and Vidyadhara, Saurav and Ki, Dayeon and Agrawal, Sweta and Pham, Chau and Kroiz, Gerson and Li, Feileen and Tao, Hudson and Srivastava, Ashay and Costa, Hevander Da and Gupta, Saloni and Rogers, Megan L. and Goncearenco, Inna and Sarli, Giuseppe and Galynker, Igor and Peskoff, Denis and Carpuat, Marine and White, Jules and Anadkat, Shyamal and Hoyle, Alexander and Resnik, Philip}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2406.06608}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We survey current techniques and practices when prompting generative AI systems like ChatGPT}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC3535">ACL 2024</abbr></div> <div id="balepur-etal-2024-artifacts" class="col-sm-8"> <div class="title">Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?</div> <div class="author"> <em>Nishant Balepur</em>, Abhilasha Ravichander, and Rachel Rudinger</div> <div class="periodical"> <em>In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Aug 2024 </div> <div class="periodical"> </div> <div style="color:red;"><b>Best Paper Award (4%) and Oral (7%) at MASC-SLL 2024</b></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2024.acl-long.555.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Multiple-choice question answering (MCQA) is often used to evaluate large language models (LLMs). To see if MCQA assesses LLMs as intended, we probe if LLMs can perform MCQA with choices-only prompts, where models must select the correct answer only from the choices. In three MCQA datasets and four LLMs, this prompt bests a majority baseline in 11/12 cases, with up to 0.33 accuracy gain. To help explain this behavior, we conduct an in-depth, black-box analysis on memorization, choice dynamics, and question inference. Our key findings are threefold. First, we find no evidence that the choices-only accuracy stems from memorization alone. Second, priors over individual choices do not fully explain choices-only accuracy, hinting that LLMs use the group dynamics of choices. Third, LLMs have some ability to infer a relevant question from choices, and surprisingly can sometimes even match the original question. We hope to motivate the use of stronger baselines in MCQA benchmarks, the design of robust MCQA datasets, and further efforts to explain LLM decision-making.</p> </div> <div class="tldr hidden"> <p>We find that LLMs don’t need the question in multiple-choice question answering to do better than random chance, and explore how</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur-etal-2024-artifacts</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Artifacts or Abduction: How Do {LLM}s Answer Multiple-Choice Questions Without the Question?}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Ravichander, Abhilasha and Rudinger, Rachel}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Bangkok, Thailand}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.acl-long.555}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{10308--10330}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{I like this paper a lot because I think the idea is super simple to understand and had really interesting results; I always wondered if I was good enough to cheat on MCQA exams, but turns out LLMs definitely are. This was also my first external collaboration!}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We find that LLMs don't need the question in multiple-choice question answering to do better than random chance, and explore how}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC3535">ACL 2024</abbr></div> <div id="balepur-etal-2024-easy" class="col-sm-8"> <div class="title">It’s Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning</div> <div class="author"> <em>Nishant Balepur</em>, Shramay Palta, and Rachel Rudinger</div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics ACL 2024</em>, Aug 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2024.findings-acl.604.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored. This process of elimination (PoE), when used with COT, can enhance self-consistency, interpretability, and tasks such as medical diagnoses of exclusion. Thus, we propose PoE with COT, where LLMs must reason toward incorrect options on multiple-choice questions. We evaluate the ability of GPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on a total of four commonsense and scientific reasoning datasets. We find that the strategy of PoE always underperforms the strategy of choosing the correct answer. The agreement of these strategies is also lower than the self-consistency of each strategy. To study these issues further, we conduct error analyses and give suggestions for future work.</p> </div> <div class="tldr hidden"> <p>We find a surprising weakness in LLMs: eliminating incorrect options in multiple-choice question answering</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur-etal-2024-easy</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{It{'}s Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Palta, Shramay and Rudinger, Rachel}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics ACL 2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Bangkok, Thailand and virtual meeting}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.findings-acl.604}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{10143--10166}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{This was the first paper I published during my Ph.D. and also my first (successful) short paper. I think short papers are under-valued; I think it's just as hard (or maybe even harder) to write a convincing argument in 4 pages, rather than inflating it to 8 pages :)}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We find a surprising weakness in LLMs: eliminating incorrect options in multiple-choice question answering}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC3535">ACL 2024</abbr></div> <div id="balepur-rudinger-2024-large" class="col-sm-8"> <div class="title">Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?</div> <div class="author"> <em>Nishant Balepur</em>, and Rachel Rudinger</div> <div class="periodical"> <em>In Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024)</em>, Aug 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2024.knowllm-1.2.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Recent work shows that large language models (LLMs) can answer multiple-choice questions using only the choices, but does this mean that MCQA leaderboard rankings of LLMs are largely influenced by abilities in choices-only settings? To answer this, we use a contrast set that probes if LLMs over-rely on choices-only shortcuts in MCQA. While previous works build contrast sets via expensive human annotations or model-generated data which can be biased, we employ graph mining to extract contrast sets from existing MCQA datasets. We use our method on UnifiedQA, a group of six commonsense reasoning datasets with high choices-only accuracy, to build an 820-question contrast set. After validating our contrast set, we test 12 LLMs, finding that these models do not exhibit reliance on choice-only shortcuts when given both the question and choices. Thus, despite the susceptibility of MCQA to high choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA leaderboards solely due to their ability to exploit choices-only shortcuts.</p> </div> <div class="tldr hidden"> <p>We study if the ability of LLMs to answer multiple-choice questions without the question is allowing models to cheat on benchmark leaderboards</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur-rudinger-2024-large</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Rudinger, Rachel}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Li, Sha and Li, Manling and Zhang, Michael JQ and Choi, Eunsol and Geva, Mor and Hase, Peter and Ji, Heng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Bangkok, Thailand}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.knowllm-1.2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{15--26}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{This was the first project I spent a few months on that led to totally negative results, so I'm grateful Rachel still encouraged me to try and publish it in a workshop. An unpopular take, but I think we more negative results papers rather than basically p-hacking our papers that work}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We study if the ability of LLMs to answer multiple-choice questions without the question is allowing models to cheat on benchmark leaderboards}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#fcbe14">EMNLP 2023</abbr></div> <div id="balepur2023expository" class="col-sm-8"> <div class="title">Expository Text Generation: Imitate, Retrieve, Paraphrase</div> <div class="author"> <em>Nishant Balepur</em>, Jie Huang, and Kevin Chen-Chuan Chang</div> <div class="periodical"> <em>In The 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023</em>, Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2305.03276.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/6elNaka-JKM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Expository documents are vital resources for conveying complex information to readers. Despite their usefulness, writing expository documents by hand is a time-consuming and labor-intensive process that requires knowledge of the domain of interest, careful content planning, and the ability to synthesize information from multiple sources. To ease these burdens, we introduce the task of expository text generation, which seeks to automatically generate an accurate and informative expository document from a knowledge source. We solve our task by developing IRP, an iterative framework that overcomes the limitations of language models and separately tackles the steps of content planning, fact selection, and rephrasing. Through experiments on three diverse datasets, we demonstrate that IRP produces high-quality expository documents that accurately inform readers.</p> </div> <div class="tldr hidden"> <p>We design an iterative planning, retrieval, and generation system to produce factual expository texts</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur2023expository</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Expository Text Generation: Imitate, Retrieve, Paraphrase}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Huang, Jie and Chang, Kevin Chen-Chuan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://youtu.be/6elNaka-JKM}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{This was my first solo-led paper (but still with some guidance from Jie and Kevin), and working on this mostly independently made me a much better researcher}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We design an iterative planning, retrieval, and generation system to produce factual expository texts}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#fcbe14">EMNLP 2023</abbr></div> <div id="balepur2023fact" class="col-sm-8"> <div class="title">Text Fact Transfer</div> <div class="author"> <em>Nishant Balepur</em>, Jie Huang, and Kevin Chen-Chuan Chang</div> <div class="periodical"> <em>In The 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023</em>, Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2310.14486.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/U01fVWUbIQw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Text style transfer is a prominent task that aims to control the style of text without inherently changing its factual content. To cover more text modification applications, such as adapting past news for current events and repurposing educational materials, we propose the task of text fact transfer, which seeks to transfer the factual content of a source text between topics without modifying its style. We find that existing language models struggle with text fact transfer, due to their inability to preserve the specificity and phrasing of the source text, and tendency to hallucinate errors. To address these issues, we design ModQGA, a framework that minimally modifies a source text with a novel combination of end-to-end question generation and specificity-aware question answering. Through experiments on four existing datasets adapted for text fact transfer, we show that ModQGA can accurately transfer factual content without sacrificing the style of the source text.</p> </div> <div class="tldr hidden"> <p>We design a model to tackle the new task of text fact transfer, a complement to style transfer that seeks to alter facts without changing style</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur2023fact</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Text Fact Transfer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Huang, Jie and Chang, Kevin Chen-Chuan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://youtu.be/U01fVWUbIQw}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We design a model to tackle the new task of text fact transfer, a complement to style transfer that seeks to alter facts without changing style}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#DC3535">ACL 2023</abbr></div> <div id="balepur2023dynamite" class="col-sm-8"> <div class="title">DynaMiTE: Discovering Explosive Topic Evolutions with User Guidance</div> <div class="author"> <em>Nishant Balepur</em>, Shivam Agarwal, Karthik Venkat Ramanan, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Susik Yoon, Diyi Yang, Jiawei Han' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: ACL 2023</em>, Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="tldr btn btn-sm z-depth-0" role="button">TL;DR</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2023.findings-acl.14.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/KAyd-QqYO6Y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Dynamic topic models (DTMs) analyze text streams to capture the evolution of topics. Despite their popularity, existing DTMs are either fully supervised, requiring expensive human annotations, or fully unsupervised, producing topic evolutions that often do not cater to a user’s needs. Further, the topic evolutions produced by DTMs tend to contain generic terms that are not indicative of their designated time steps. To address these issues, we propose the task of discriminative dynamic topic discovery. This task aims to discover topic evolutions from temporal corpora that distinctly align with a set of user-provided category names and uniquely capture topics at each time step. We solve this task by developing DynaMiTE, a framework that ensembles semantic similarity, category indicative, and time indicative scores to produce informative topic evolutions. Through experiments on three diverse datasets, including the use of a newly-designed human evaluation experiment, we demonstrate that DynaMiTE is a practical and efficient framework for helping users discover high-quality topic evolutions suited to their interests.</p> </div> <div class="tldr hidden"> <p>We design a model to perform dynamic topic modeling while using guidance from user-provided topics of interest</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">balepur2023dynamite</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DynaMiTE: Discovering Explosive Topic Evolutions with User Guidance}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Balepur, Nishant and Agarwal, Shivam and Ramanan, Karthik Venkat and Yoon, Susik and Yang, Diyi and Han, Jiawei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: ACL 2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{194--217}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.findings-acl.14}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://youtu.be/KAyd-QqYO6Y}</span><span class="p">,</span>
  <span class="na">tldr</span> <span class="p">=</span> <span class="s">{We design a model to perform dynamic topic modeling while using guidance from user-provided topics of interest}</span><span class="p">,</span>
  <span class="na">thoughts</span> <span class="p">=</span> <span class="s">{This was the first paper I ever wrote, so I obviously look back and cringe. I'm no longer interested in the topic and barely remember what I did, but do remember enjoying the writing process a lot}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Nishant Balepur. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?44f5be8c18d980ffaa8492fdc33e3271"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1BY15F84QB"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1BY15F84QB");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>