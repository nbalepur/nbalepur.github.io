@article{balepur2023artifact,
  abbr= "Preprint",
  title={Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?},
  author={Balepur, Nishant and Ravichander, Abhilasha and Rudinger, Rachel},
  journal={arXiv preprint},
  year={2024},
  selected={true},
  bibtex_show={true},
  url = "https://arxiv.org/abs/2402.12483",
  pdf = "https://arxiv.org/pdf/2402.12483.pdf",
  abstract = "Multiple-choice question answering (MCQA) is often used to evaluate large language models (LLMs). To see if MCQA assesses LLMs as intended, we probe if LLMs can perform MCQA with \emph{choices-only} prompts, where models must select the correct answer only from the choices. In three MCQA datasets and four LLMs, this prompt bests a majority baseline in 11/12 cases, with up to 0.33 accuracy gain. To help explain this behavior, we conduct an in-depth, black-box analysis on memorization, choice dynamics, and question inference. Our key findings are threefold. First, we find no evidence that the choices-only accuracy stems from memorization alone. Second, priors over individual choices do not fully explain choices-only accuracy, hinting that LLMs use the group dynamics of choices. Third, LLMs have some ability to infer a relevant question from choices, and surprisingly can sometimes even match the original question. We hope to motivate the use of stronger baselines in MCQA benchmarks, the design of robust MCQA datasets, and further efforts to explain LLM decision-making.",
}

@article{shu2023KARL,
  abbr= "Preprint",
  title={KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students},
  author={Shu, Matthew and Balepur, Nishant and Feng, Shi and Boyd-Graber, Jordan},
  journal={arXiv preprint},
  year={2024},
  selected={false},
  bibtex_show={true},
  url = "https://arxiv.org/abs/2402.12291",
  pdf = "https://arxiv.org/pdf/2402.12291.pdf",
  abstract = "Flashcard schedulers are tools that rely on 1) student models to predict the flashcards a student knows; and 2) teaching policies to schedule cards based on these predictions. Existing student models, however, only use flashcard-level features, like the student's past responses, ignoring the semantic ties of flashcards. Deep Knowledge Tracing (DKT) models can capture semantic relations with language models, but are inefficient, lack content-rich datasets for evaluation, and require robust teaching policies. To address these issues, we design KARL, a DKT-inspired student model that uses retrieval and BERT embeddings for efficient and accurate student recall predictions. To test KARL, we collect a new dataset of diverse study history on trivia questions. KARL bests existing student models in AUC and calibration error. Finally, we propose a novel teaching policy that exploits the predictive power of DKT models to deploy KARL online. Based on 27 learners and 32 6-day study trajectories, KARL shows the ability to enhance medium-term educational learning, proving its efficacy for scheduling.",
}

@article{balepur2023not,
  abbr= "Preprint",
  title={It's Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning},
  author={Balepur, Nishant and Palta, Shramay and Rudinger, Rachel},
  journal={arXiv preprint},
  year={2023},
  selected={true},
  bibtex_show={true},
  url = "https://arxiv.org/abs/2311.07532",
  pdf = "https://arxiv.org/pdf/2311.07532.pdf",
  abstract = "Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored. This process of elimination (PoE), when used with COT, can enhance self-consistency, interpretability, and tasks such as medical diagnoses of exclusion. Thus, we propose PoE with COT, where LLMs must reason toward incorrect options on multiple-choice questions. We evaluate the ability of GPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on a total of four commonsense and scientific reasoning datasets. We find that the strategy of PoE always underperforms the strategy of choosing the correct answer. The agreement of these strategies is also lower than the self-consistency of each strategy. To study these issues further, we conduct error analyses and give suggestions for future work.",
}


@inproceedings{balepur2023expository,
  abbr= "EMNLP 2023",
  title={Expository Text Generation: Imitate, Retrieve, Paraphrase},
  author={Balepur, Nishant and Huang, Jie and Chang, Kevin Chen-Chuan},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023},
  year={2023},
  selected={true},
  bibtex_show={true},
  url = "https://arxiv.org/abs/2305.03276",
  pdf = "https://arxiv.org/pdf/2305.03276.pdf",
  video = "https://youtu.be/6elNaka-JKM",
  abstract = "Expository documents are vital resources for conveying complex information to readers. Despite their usefulness, writing expository documents by hand is a time-consuming and labor-intensive process that requires knowledge of the domain of interest, careful content planning, and the ability to synthesize information from multiple sources. To ease these burdens, we introduce the task of expository text generation, which seeks to automatically generate an accurate and informative expository document from a knowledge source. We solve our task by developing IRP, an iterative framework that overcomes the limitations of language models and separately tackles the steps of content planning, fact selection, and rephrasing. Through experiments on three diverse datasets, we demonstrate that IRP produces high-quality expository documents that accurately inform readers.",
}

@inproceedings{balepur2023fact,
  abbr= "EMNLP 2023",
  title={Text Fact Transfer},
  author={Balepur, Nishant and Huang, Jie and Chang, Kevin Chen-Chuan},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023},
  year={2023},
  selected={false},
  bibtex_show={true},
  url = "https://arxiv.org/abs/2310.14486",
  pdf = "https://arxiv.org/pdf/2310.14486.pdf",
  video = "https://youtu.be/U01fVWUbIQw",
  abstract = "Text style transfer is a prominent task that aims to control the style of text without inherently changing its factual content. To cover more text modification applications, such as adapting past news for current events and repurposing educational materials, we propose the task of text fact transfer, which seeks to transfer the factual content of a source text between topics without modifying its style. We find that existing language models struggle with text fact transfer, due to their inability to preserve the specificity and phrasing of the source text, and tendency to hallucinate errors. To address these issues, we design ModQGA, a framework that minimally modifies a source text with a novel combination of end-to-end question generation and specificity-aware question answering. Through experiments on four existing datasets adapted for text fact transfer, we show that ModQGA can accurately transfer factual content without sacrificing the style of the source text.",
}

@inproceedings{balepur2023dynamite,
  abbr={ACL 2023},
  title={DynaMiTE: Discovering Explosive Topic Evolutions with User Guidance},
  author={Balepur, Nishant and Agarwal, Shivam and Ramanan, Karthik Venkat and Yoon, Susik and Yang, Diyi and Han, Jiawei},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={194--217},
  year={2023},
  selected={false},
  bibtex_show={true},
  url = "https://aclanthology.org/2023.findings-acl.14",
  pdf = "https://aclanthology.org/2023.findings-acl.14.pdf",
  video = "https://youtu.be/KAyd-QqYO6Y",
  abstract = "Dynamic topic models (DTMs) analyze text streams to capture the evolution of topics. Despite their popularity, existing DTMs are either fully supervised, requiring expensive human annotations, or fully unsupervised, producing topic evolutions that often do not cater to a userâ€™s needs. Further, the topic evolutions produced by DTMs tend to contain generic terms that are not indicative of their designated time steps. To address these issues, we propose the task of discriminative dynamic topic discovery. This task aims to discover topic evolutions from temporal corpora that distinctly align with a set of user-provided category names and uniquely capture topics at each time step. We solve this task by developing DynaMiTE, a framework that ensembles semantic similarity, category indicative, and time indicative scores to produce informative topic evolutions. Through experiments on three diverse datasets, including the use of a newly-designed human evaluation experiment, we demonstrate that DynaMiTE is a practical and efficient framework for helping users discover high-quality topic evolutions suited to their interests.",
}

@article{balepur2023mastering,
  abbr= "Preprint",
  title={Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation},
  author={Balepur, Nishant and Huang, Jie and Moorjani, Samraj and Sundaram, Hari and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint},
  year={2023},
  bibtex_show={true},
  url = "https://arxiv.org/abs/2305.14750",
  pdf = "https://arxiv.org/pdf/2305.14750.pdf",
  abstract = "When answering complex questions, large language models (LLMs) may produce answers that do not satisfy all criteria of the question. While existing self-evaluation techniques aim to detect if such answers are correct, these techniques are unable to determine which criteria of the question are satisfied by the generated answers. To address this issue, we propose answer-based claim decomposition (ABCD), a prompting strategy that decomposes questions into a series of true/false claims that can be used to verify which criteria of the input question an answer satisfies. Using the decomposed ABCD claims, we perform fine-grained self-evaluation. Through preliminary experiments on three datasets, including a newly-collected challenge dataset ObscureQA, we find that GPT-3.5 has some ability to determine to what extent its answer satisfies the criteria of the input question, and can give insights into the errors and knowledge gaps of the model.",
}
