@inproceedings{balepur2023dynamite,
  abbr={ACL 2023},
  title={DynaMiTE: Discovering Explosive Topic Evolutions with User Guidance},
  author={Balepur, Nishant and Agarwal, Shivam and Ramanan, Karthik Venkat and Yoon, Susik and Yang, Diyi and Han, Jiawei},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={194--217},
  year={2023},
  selected={true},
  bibtex_show={true},
  url = "https://aclanthology.org/2023.findings-acl.14.pdf",
  pdf = "https://aclanthology.org/2023.findings-acl.14.pdf",
  abstract = "Dynamic topic models (DTMs) analyze text streams to capture the evolution of topics. Despite their popularity, existing DTMs are either fully supervised, requiring expensive human annotations, or fully unsupervised, producing topic evolutions that often do not cater to a userâ€™s needs. Further, the topic evolutions produced by DTMs tend to contain generic terms that are not indicative of their designated time steps. To address these issues, we propose the task of discriminative dynamic topic discovery. This task aims to discover topic evolutions from temporal corpora that distinctly align with a set of user-provided category names and uniquely capture topics at each time step. We solve this task by developing DynaMiTE, a framework that ensembles semantic similarity, category indicative, and time indicative scores to produce informative topic evolutions. Through experiments on three diverse datasets, including the use of a newly-designed human evaluation experiment, we demonstrate that DynaMiTE is a practical and efficient framework for helping users discover high-quality topic evolutions suited to their interests.",
}

@article{balepur2023expository,
  abbr= "Preprint",
  title={Expository Text Generation: Imitate, Retrieve, Paraphrase},
  author={Balepur, Nishant and Huang, Jie and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint},
  year={2023},
  selected={true},
  bibtex_show={true},
  url = "https://arxiv.org/pdf/2305.03276.pdf",
  pdf = "https://arxiv.org/pdf/2305.03276.pdf",
  abstract = "Expository documents are vital resources for conveying complex information to readers. Despite their usefulness, writing expository documents by hand is a time-consuming and labor-intensive process that requires knowledge of the domain of interest, careful content planning, and the ability to synthesize information from multiple sources. To ease these burdens, we introduce the task of expository text generation, which seeks to automatically generate an accurate and informative expository document from a knowledge source. We solve our task by developing IRP, an iterative framework that overcomes the limitations of language models and separately tackles the steps of content planning, fact selection, and rephrasing. Through experiments on three diverse datasets, we demonstrate that IRP produces high-quality expository documents that accurately inform readers.",
}

@article{balepur2023mastering,
  abbr= "Preprint",
  title={Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation},
  author={Balepur, Nishant and Huang, Jie and Moorjani, Samraj and Sundaram, Hari and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint},
  year={2023},
  bibtex_show={true},
  url = "https://arxiv.org/pdf/2305.14750.pdf",
  pdf = "https://arxiv.org/pdf/2305.14750.pdf",
  abstract = "When answering complex questions, large language models (LLMs) may produce answers that do not satisfy all criteria of the question. While existing self-evaluation techniques aim to detect if such answers are correct, these techniques are unable to determine which criteria of the question are satisfied by the generated answers. To address this issue, we propose answer-based claim decomposition (ABCD), a prompting strategy that decomposes questions into a series of true/false claims that can be used to verify which criteria of the input question an answer satisfies. Using the decomposed ABCD claims, we perform fine-grained self-evaluation. Through preliminary experiments on three datasets, including a newly-collected challenge dataset ObscureQA, we find that GPT-3.5 has some ability to determine to what extent its answer satisfies the criteria of the input question, and can give insights into the errors and knowledge gaps of the model.",
}
